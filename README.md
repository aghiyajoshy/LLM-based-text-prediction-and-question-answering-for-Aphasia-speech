# LLM-based-text-prediction-and-question-answering-for-Aphasia-speech
This project develops a LLM based system to assist aphasia patients by predicting missing words and answering questions from fragmented or disfluent speech. It combines speech-to-text transcription (AssemblyAI), masked language modeling (RoBERTa), and question answering to reconstruct meaningful sentences and provide relevant responses.
Aphasia Speech Assistant using RoBERTa
This project builds a language model-based system to assist patients with Aphasia â€” a language disorder that affects speech production and comprehension. The system performs text prediction and question answering on fragmented or disfluent speech using RoBERTa-based models, helping reconstruct meaningful communication.

ğŸš€ Features
âœ… Speech-to-Text Transcription using AssemblyAI

âœ… Masked Word Prediction using RoBERTa (Masked Language Model)

âœ… Question Answering using fine-tuned RoBERTa QA model

âœ… Handles disfluencies and speech gaps often seen in aphasia patients

âœ… Evaluation Metrics: Accuracy, Precision, F1 Score, BLEU Score

ğŸ’¡ Motivation
Aphasia patients often struggle with missing words, fragmented speech, or incomplete sentences. Traditional speech analysis tools are not designed for such irregular input. This project leverages modern Large Language Models (LLMs) to:

Reconstruct missing words

Understand patient intent

Answer questions from partial speech

Assist therapy and communication

ğŸ”§ Technologies Used
RoBERTa-base (Masked Language Model)

RoBERTa-base-SQuAD2 (Question Answering Model)

Hugging Face Transformers

PyTorch

AssemblyAI (Speech-to-Text API)

Python 3.8+

ğŸ“Š Evaluation Metrics
Metric	Purpose
Accuracy	Correct full predictions
Precision	Reliability of correct predictions
F1 Score	Balance between precision and recall
BLEU Score	Similarity between predicted and reference text

ğŸ—‚ Dataset
Custom dataset generated from speech samples with disfluency masking and QA pairs extracted.

The project can easily adapt to real-world speech datasets (e.g. AphasiaBank).

ğŸ”¨ Installation
1ï¸âƒ£ Clone this repository:

git clone https://github.com/your-username/aphasia-speech-assistant.git
cd aphasia-speech-assistant

2ï¸âƒ£ Install required packages:

pip install torch transformers assemblyai datasets

3ï¸âƒ£ Set up AssemblyAI API key in your code:

aai.settings.api_key = "YOUR_API_KEY"

ğŸ§ª Running the Project
Upload speech files (.wav) to transcribe and process.

The system automatically:

Transcribes speech

Extracts patient utterances

Masks disfluencies

Predicts missing words

Answers questions from the transcript

ğŸ“ˆ Results
The system achieves good performance in reconstructing sentences from aphasia speech and accurately answering simple context-based questions. Evaluation is done using both strict (accuracy) and flexible (BLEU score) metrics.

ğŸ“š References
RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al.)

Hugging Face Transformers

AssemblyAI Speech-to-Text API

Aphasia Research Papers

ğŸ“Œ Future Work
Fine-tune RoBERTa on aphasia-specific speech datasets

Extend model to handle more severe disfluencies

Add real-time speech correction interface

